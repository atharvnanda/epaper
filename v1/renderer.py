"""
Step 3: Render translated articles into a standalone HTML file.

If articles_ocr.json exists (generated by ocr.py), the renderer merges
adjacent OCR text blocks into logical regions (headline, body) per
article and creates one overlay per region.  Photos and graphics between
regions stay visible.
"""

import json
import os

from jinja2 import Environment, FileSystemLoader

DATA_DIR = "data"
OUTPUT_DIR = "output"
TEMPLATE_DIR = "templates"

COORD_SPACE_W = 1128
COORD_SPACE_H = 2050

# Body text assignment is truncated to per-region capacity estimated from
# overlay geometry (box width/height + OCR-derived font-size proxy).
CHAR_FIT_SAFETY = float(os.getenv("CHAR_FIT_SAFETY", "0.90"))


def _paths(date_str: str):
    """Return date-namespaced file paths."""
    data_dir = os.path.join(DATA_DIR, date_str)
    output_dir = os.path.join(OUTPUT_DIR, date_str)
    ocr_file = os.path.join(data_dir, "articles_ocr.json")
    translated_file = os.path.join(data_dir, "articles_translated.json")
    output_html = os.path.join(output_dir, "index.html")
    return ocr_file, translated_file, output_dir, output_html


def _convert_to_pct(pages):
    """Convert absolute px coordinates to percentage-based for responsive overlay."""
    for pg in pages:
        for art in pg.get("articles", []):
            art["top_pct"] = art["top"] / COORD_SPACE_H * 100
            art["left_pct"] = art["left"] / COORD_SPACE_W * 100
            art["width_pct"] = art["width"] / COORD_SPACE_W * 100
            art["height_pct"] = art["height"] / COORD_SPACE_H * 100


def _take_text_chunk(text: str, cap: int):
    """Take up to cap chars from text, preferring a natural break.

    Returns (chunk, remainder).
    """
    txt = (text or "").lstrip()
    if not txt or cap <= 0:
        return "", txt
    if len(txt) <= cap:
        return txt.rstrip(), ""

    # 1) Prefer finishing the current sentence shortly *after* cap.
    # This avoids abrupt mid-sentence endings while keeping overflow bounded.
    sentence_marks = ".!?"
    extend = max(24, int(cap * 0.18))
    scan_end = min(len(txt), cap + extend)
    for i in range(cap, scan_end):
        if txt[i] in sentence_marks:
            cut = i + 1
            chunk = txt[:cut].rstrip()
            remainder = txt[cut:].lstrip()
            return chunk, remainder

    # 2) If no forward sentence end, prefer a prior sentence boundary.
    min_idx = max(1, int(cap * 0.55))
    for i in range(cap, min_idx - 1, -1):
        if txt[i - 1] in sentence_marks:
            cut = i
            chunk = txt[:cut].rstrip()
            remainder = txt[cut:].lstrip()
            return chunk, remainder

    # 3) Fallback to clean word/punctuation boundary near cap.
    cut = -1
    for i in range(cap, min_idx - 1, -1):
        ch = txt[i - 1]
        if ch.isspace() or ch in ".,;:!?)]}—-":
            cut = i
            break

    if cut == -1:
        cut = cap

    chunk = txt[:cut].rstrip()
    remainder = txt[cut:].lstrip()
    return chunk, remainder


def _estimate_body_char_cap(region: dict) -> int:
    """Estimate how many body chars can fit in this region.

    Uses region geometry and the same body font heuristic used in template JS.
    """
    box_w = max(1.0, (region.get("width_pct", 0.0) / 100.0) * COORD_SPACE_W - 8.0)
    box_h = max(1.0, (region.get("height_pct", 0.0) / 100.0) * COORD_SPACE_H - 4.0)
    avg_h = max(8.0, float(region.get("avg_block_h", 12.0)))

    # Mirror body font heuristic from templates/epaper.html.j2
    font_size = min(avg_h * 0.52, box_h * 0.18, 16.0)
    font_size = max(font_size, 8.2)

    char_w = max(1.0, font_size * 0.52)
    line_h = max(1.0, font_size * 1.35)
    chars_per_line = max(1, int(box_w // char_w))
    lines = max(1, int(box_h // line_h))

    cap = int(chars_per_line * lines * CHAR_FIT_SAFETY)
    return max(1, cap)


def _deoverlap_body_regions(regions):
    """Trim horizontal overlap between neighboring body regions.

    Keeps visual columns side-by-side instead of letting one overlay intrude
    into the next.
    """
    body = [r for r in regions if r.get("role") == "body"]
    if len(body) <= 1:
        return

    # Multiple passes to settle pairwise overlaps.
    for _ in range(2):
        for i in range(len(body)):
            a = body[i]
            ax0 = a["left_pct"]
            ax1 = a["left_pct"] + a["width_pct"]
            ay0 = a["top_pct"]
            ay1 = a["top_pct"] + a["height_pct"]
            ah = max(0.001, ay1 - ay0)

            for j in range(i + 1, len(body)):
                b = body[j]
                bx0 = b["left_pct"]
                bx1 = b["left_pct"] + b["width_pct"]
                by0 = b["top_pct"]
                by1 = b["top_pct"] + b["height_pct"]
                bh = max(0.001, by1 - by0)

                # Only treat as conflicting columns if they overlap vertically enough.
                ov_y = min(ay1, by1) - max(ay0, by0)
                if ov_y <= 0:
                    continue
                if ov_y / min(ah, bh) < 0.45:
                    continue

                ov_x0 = max(ax0, bx0)
                ov_x1 = min(ax1, bx1)
                if ov_x1 <= ov_x0:
                    continue

                # Determine left vs right region by center x.
                ac = (ax0 + ax1) / 2
                bc = (bx0 + bx1) / 2
                if ac <= bc:
                    left_r, right_r = a, b
                else:
                    left_r, right_r = b, a

                lx0 = left_r["left_pct"]
                lx1 = left_r["left_pct"] + left_r["width_pct"]
                rx0 = right_r["left_pct"]
                rx1 = right_r["left_pct"] + right_r["width_pct"]

                ov0 = max(lx0, rx0)
                ov1 = min(lx1, rx1)
                if ov1 <= ov0:
                    continue

                seam = (ov0 + ov1) / 2
                gutter = 0.10

                new_lx1 = min(lx1, seam - gutter / 2)
                new_rx0 = max(rx0, seam + gutter / 2)

                # Keep sane minimum widths.
                if new_lx1 - lx0 < 0.8 or rx1 - new_rx0 < 0.8:
                    continue

                left_r["left_pct"] = round(lx0, 3)
                left_r["width_pct"] = round(new_lx1 - lx0, 3)
                right_r["left_pct"] = round(new_rx0, 3)
                right_r["width_pct"] = round(rx1 - new_rx0, 3)

                # Refresh local values if current pair included a or b.
                if left_r is a or right_r is a:
                    ax0 = a["left_pct"]
                    ax1 = a["left_pct"] + a["width_pct"]
                if left_r is b or right_r is b:
                    bx0 = b["left_pct"]
                    bx1 = b["left_pct"] + b["width_pct"]

    # Recompute box-fit capacities after any width adjustments.
    for r in body:
        r["char_cap"] = _estimate_body_char_cap(r)


# ────────────────────────────────────────────────────────────────────
#  Merge OCR blocks into logical regions per article
# ────────────────────────────────────────────────────────────────────

_ROLE_PRIORITY = {"headline": 0, "subheadline": 1, "body": 2, "byline": 3}


def _spatial_cluster(blocks, gap_x_pct=3.0, gap_y_pct=2.0):
    """Cluster OCR blocks that are spatially adjacent (union-find).

    Two blocks are considered neighbours if their bounding boxes are
    within *gap_x_pct* horizontally AND *gap_y_pct* vertically.
    Returns a list of lists (each inner list is a cluster of blocks).
    """
    n = len(blocks)
    if n <= 1:
        return [blocks] if blocks else []

    # Precompute bounding edges for each block
    edges = []
    for b in blocks:
        edges.append((
            b["left_pct"],                        # x0
            b["left_pct"] + b["width_pct"],       # x1
            b["top_pct"],                         # y0
            b["top_pct"] + b["height_pct"],       # y1
        ))

    # Union-Find
    parent = list(range(n))

    def find(i):
        while parent[i] != i:
            parent[i] = parent[parent[i]]
            i = parent[i]
        return i

    def union(i, j):
        ri, rj = find(i), find(j)
        if ri != rj:
            parent[ri] = rj

    for i in range(n):
        x0i, x1i, y0i, y1i = edges[i]
        for j in range(i + 1, n):
            x0j, x1j, y0j, y1j = edges[j]
            x_close = not (x1i + gap_x_pct < x0j or x1j + gap_x_pct < x0i)
            y_close = not (y1i + gap_y_pct < y0j or y1j + gap_y_pct < y0i)
            if x_close and y_close:
                union(i, j)

    groups = {}
    for i in range(n):
        r = find(i)
        groups.setdefault(r, []).append(blocks[i])

    return list(groups.values())


def _column_cluster(blocks, gap_y_pct=2.5):
    """Cluster body text blocks by column, then vertically within each column.

    Newspaper body text sits in narrow columns.  We detect column
    boundaries by binning narrow blocks' horizontal midpoints into
    fixed-width bins, then assigning each block to its bin.

    Wide blocks (spanning multiple bins) are duplicated into each bin
    they touch — but each bin's bounding box stays column-narrow.

    Within each column-bin, adjacent blocks are merged vertically if
    the vertical gap is small.
    """
    if not blocks:
        return []

    # Estimate column width from the article zone span
    all_lefts = [b["left_pct"] for b in blocks]
    all_rights = [b["left_pct"] + b["width_pct"] for b in blocks]
    zone_left = min(all_lefts)
    zone_right = max(all_rights)
    zone_width = zone_right - zone_left

    # Typical newspaper columns are ~15-20% of page width
    # Estimate number of columns from zone width
    est_cols = max(1, round(zone_width / 18.0))
    bin_width = zone_width / est_cols if est_cols > 0 else zone_width

    # If the zone is narrow (1 column or less), just do vertical clustering
    if est_cols <= 1 or bin_width < 8:
        return _vertical_cluster(blocks, gap_y_pct)

    # ── Assign blocks to column bins ──
    col_bins = {}  # bin_index -> list of blocks
    for b in blocks:
        b_mid = b["left_pct"] + b["width_pct"] / 2
        b_left = b["left_pct"]
        b_right = b["left_pct"] + b["width_pct"]

        # Which bins does this block touch?
        bin_start = int((b_left - zone_left) / bin_width)
        bin_end = int((b_right - zone_left) / bin_width)

        # Narrow block: assign to the bin of its midpoint only
        if b["width_pct"] < bin_width * 1.3:
            bin_idx = int((b_mid - zone_left) / bin_width)
            bin_idx = max(0, min(bin_idx, est_cols - 1))
            col_bins.setdefault(bin_idx, []).append(b)
        else:
            # Wide block: assign to the bin with most overlap
            best_bin = max(
                range(max(0, bin_start), min(bin_end + 1, est_cols)),
                key=lambda bi: (
                    min(b_right, zone_left + (bi + 1) * bin_width) -
                    max(b_left, zone_left + bi * bin_width)
                ),
                default=0
            )
            col_bins.setdefault(best_bin, []).append(b)

    # ── Within each column bin: vertically cluster adjacent blocks ──
    all_clusters = []
    for _bin_idx, col_blks in sorted(col_bins.items()):
        if not col_blks:
            continue
        vert_groups = _vertical_cluster(col_blks, gap_y_pct)
        all_clusters.extend(vert_groups)

    return all_clusters


def _vertical_cluster(blocks, gap_y_pct=2.5):
    """Cluster blocks that are vertically adjacent (small Y gap)."""
    if not blocks:
        return []
    if len(blocks) == 1:
        return [blocks]

    blocks = sorted(blocks, key=lambda b: b["top_pct"])
    groups = [[blocks[0]]]
    for b in blocks[1:]:
        prev_bottom = max(bb["top_pct"] + bb["height_pct"] for bb in groups[-1])
        gap = b["top_pct"] - prev_bottom
        if gap > gap_y_pct:
            groups.append([b])
        else:
            groups[-1].append(b)
    return groups


def _merge_blocks_into_regions(art):
    """Merge OCR blocks into spatial clusters, then into overlay regions.

    - Headlines/subheadlines: spatial clustering (they may span columns).
    - Body/byline text: column-based clustering so that columns adjacent
      to a photo don't merge into one wide box covering the photo.

    Returns a list of region dicts sorted top-to-bottom.
    """
    blocks = art.get("text_blocks", [])
    if not blocks:
        return []

    by_role = {}
    for b in blocks:
        role = b.get("role", "body")
        by_role.setdefault(role, []).append(b)

    regions = []

    for role, blks in by_role.items():
        if not blks:
            continue

        if role in ("headline", "subheadline"):
            clusters = _spatial_cluster(blks, gap_x_pct=8.0, gap_y_pct=3.0)
        else:
            # Body / byline: column-aware clustering
            clusters = _column_cluster(blks, gap_y_pct=2.5)

        for idx, grp in enumerate(clusters):
            top = min(b["top_pct"] for b in grp)
            left = min(b["left_pct"] for b in grp)
            bottom = max(b["top_pct"] + b["height_pct"] for b in grp)
            right = max(b["left_pct"] + b["width_pct"] for b in grp)

            avg_height = sum(b["height"] for b in grp) / len(grp)
            ocr_char_count = sum(len((b.get("ocr_text") or "").strip()) for b in grp)
            region = {
                "role": role,
                "top_pct": round(top, 3),
                "left_pct": round(left, 3),
                "width_pct": round(right - left, 3),
                "height_pct": round(bottom - top, 3),
                "avg_block_h": round(avg_height, 1),
                "block_count": len(grp),
                "ocr_char_count": int(ocr_char_count),
                "_body_order": idx if role == "body" else -1,
            }
            if role == "body":
                region["char_cap"] = _estimate_body_char_cap(region)
            else:
                # For non-body regions, retain OCR-char metadata only.
                region["char_cap"] = int(ocr_char_count)

            regions.append(region)

    def _sort_key(r):
        role_rank = _ROLE_PRIORITY.get(r["role"], 9)
        if r["role"] == "body":
            # Preserve column-cluster order for body text (better continuity
            # in multi-column stories).
            return (role_rank, r.get("_body_order", 0))
        return (role_rank, r["top_pct"], r["left_pct"])

    regions.sort(key=_sort_key)

    # Ensure neighboring body columns don't overlap.
    _deoverlap_body_regions(regions)

    for r in regions:
        if "_body_order" in r:
            del r["_body_order"]
    return regions


def _assign_text_to_regions(art, regions):
    """Assign headline_en / body_en to the merged regions."""

    headline_en = (art.get("headline_en") or "").strip()
    body_en = (art.get("body_en") or "").strip()

    headline_regions = [r for r in regions if r["role"] == "headline"]
    subhead_regions = [r for r in regions if r["role"] == "subheadline"]
    body_regions = [r for r in regions if r["role"] == "body"]
    byline_regions = [r for r in regions if r["role"] == "byline"]

    # ── Headlines ──
    if headline_regions:
        if len(headline_regions) == 1:
            headline_regions[0]["en_text"] = headline_en
        else:
            words = headline_en.split()
            chunk = max(1, len(words) // len(headline_regions))
            for i, hr in enumerate(headline_regions):
                start = i * chunk
                end = start + chunk if i < len(headline_regions) - 1 else len(words)
                hr["en_text"] = " ".join(words[start:end])

    # ── Subheadlines ──
    body_lines = [s.strip() for s in body_en.split("\n") if s.strip()]
    sub_offset = 0
    for sr in subhead_regions:
        if sub_offset < len(body_lines):
            sr["en_text"] = body_lines[sub_offset]
            sub_offset += 1
        else:
            sr["en_text"] = ""

    # ── Body: sequential truncation by box-fit per-region char cap ──
    remaining_text = " ".join(body_lines[sub_offset:]).strip()
    for br in body_regions:
        cap = int(br.get("char_cap", 0) or 0)
        source_text = remaining_text
        chunk, remaining_text = _take_text_chunk(remaining_text, cap)
        br["en_text"] = chunk
        br["assigned_chars"] = len(chunk)
        br["truncated"] = len((source_text or "").lstrip()) > len(chunk)

    art["body_chars_unassigned"] = len(remaining_text)

    # ── Bylines: leave blank (hide Hindi, don't show garbage) ──
    for bl in byline_regions:
        bl["en_text"] = ""

    # Default
    for r in regions:
        if "en_text" not in r:
            r["en_text"] = ""


def render_html(date_str: str):
    """Load OCR or translated data and render to output/{date}/index.html."""

    ocr_file, translated_file, output_dir, output_html = _paths(date_str)

    # Prefer OCR data if available
    source_file = ocr_file if os.path.exists(ocr_file) else translated_file
    use_ocr = source_file == ocr_file

    if not os.path.exists(source_file):
        print(f"  ERROR: {source_file} not found.")
        return

    print(f"  Using {'OCR' if use_ocr else 'translated'} data: {source_file}")

    with open(source_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    os.makedirs(output_dir, exist_ok=True)

    # Convert zone coordinates to percentages
    _convert_to_pct(data["pages"])

    # If OCR data: merge blocks into regions and assign text
    total_regions = 0
    if use_ocr:
        for pg in data["pages"]:
            for art in pg["articles"]:
                regions = _merge_blocks_into_regions(art)
                _assign_text_to_regions(art, regions)
                art["regions"] = regions
                total_regions += len(regions)

    env = Environment(loader=FileSystemLoader(TEMPLATE_DIR))
    template = env.get_template("epaper.html.j2")

    html = template.render(
        date=date_str,
        pages=data["pages"],
        use_ocr=use_ocr,
    )

    with open(output_html, "w", encoding="utf-8") as f:
        f.write(html)

    total_articles = sum(len(pg["articles"]) for pg in data["pages"])
    print(f"  Done! Generated {output_html}")
    print(f"  Pages: {len(data['pages'])}, Article zones: {total_articles}")
    if use_ocr:
        print(f"  Merged text regions: {total_regions}")
    print(f"  Open {output_html} in your browser to view.")


if __name__ == "__main__":
    import sys
    date = sys.argv[1] if len(sys.argv) > 1 else "2026-02-25"
    render_html(date)
